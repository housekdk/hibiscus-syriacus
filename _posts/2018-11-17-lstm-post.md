---
title: "RNN & LSTM Study"
date: 2018-12-27 08:26:28 -0400
categories: RNN, LSTM
tags: [test]
use_math: true
---

### 개요

ㅡ DNN의 hidden layer는 중간 계산 결과를 거쳐 가는 layer
- RNN의 hidden layer는 이전 정보를 기억하는 역할


## RNN

## LSTM

\begin{align} 
i & = \sigma(x_tU^i + s_{t-1} W^i) \\ 
f & = \sigma(x_t U^f +s_{t-1} W^f) \\ 
o & = \sigma(x_t U^o + s_{t-1} W^o) \\ 
g & = \tanh(x_t U^g + s_{t-1}W^g) \\ 
c_t & = c_{t-1} \circ f + g \circ i \\ 
s_t & = \tanh(c_t) \circ o 
\end{align}
